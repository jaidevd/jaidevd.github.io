<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>objectdetection on Jaidev&#39;s Blog</title>
    <link>https://jaidevd.com/tags/objectdetection/</link>
    <description>Recent content in objectdetection on Jaidev&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Sep 2022 19:47:39 +0530</lastBuildDate><atom:link href="https://jaidevd.com/tags/objectdetection/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Effective Train/Test Stratification for Object Detection</title>
      <link>https://jaidevd.com/posts/obj-detection-stratification/</link>
      <pubDate>Fri, 30 Sep 2022 19:47:39 +0530</pubDate>
      
      <guid>https://jaidevd.com/posts/obj-detection-stratification/</guid>
      <description>There&amp;rsquo;s an unavoidable, inherent difficulty in fine-tuning deep neural networks for specific tasks, which primarily stems from the lack of training data. It would seem ridiculous to a layperson that a pretrained vision model (containing millions of parameters, trained on millions of images) could learn to solve highly specific problems. Therefore, when fine-tuned models do perform well, they seem all the more miraculous. But on the other hand, we also know that it is easier to move from the general to the specific, than the reverse.</description>
    </item>
    
  </channel>
</rss>
