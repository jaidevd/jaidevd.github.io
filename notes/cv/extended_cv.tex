\documentclass{resume} % Use the custom resume.cls style

\usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry} % Document margins
\usepackage{hyperref}
\hypersetup{colorlinks=true}

\name{Jaidev Deshpande} % Your name
\address{S-390, Ground Floor \\ Greater Kailash 1 \\ New Delhi 110048} % Your address
\address{(+91)-844-733-5686 \\ deshpande.jaidev@gmail.com} % Your phone number and email
\address{Website: \url{http://jaidevd.github.io}}

\begin{document}

%----------------------------------------------------------------------------------------
%	EDUCATION SECTION
%----------------------------------------------------------------------------------------

% \begin{rSection}{Education}
% 
% \textbf{University of Pune} \hfill {\em July 2012} \\ 
% B.E. in Electronics
% 
% \end{rSection}

%----------------------------------------------------------------------------------------
%	WORK EXPERIENCE SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Experience}
    \begin{rSubsection}{Gramener Technology Solutions Pvt Ltd}{Novemer 2018 - Present}
        {Principal Data Scientist}{New Delhi}
	    \begin{itemize}
		    \item Part of the product team that develops and maintains
			    \href{https://github.com/gramener/gramex}{Gramex}, a no-code data analytics platform.
		    \item Consulting on various ML projects.
	    \end{itemize}
    \end{rSubsection}
	\begin{rSubsection}{Juxt Smartmandate Analytical Solutions Pvt Ltd}{December
	    2016 - Novemer 2018}{Chief Data Scientist}{New Delhi}
		\begin{itemize}
		    \item \textbf{Leading the Data Science Team} My day to day job at JSM
			involves transforming different business problems into a data
			scientistâ€™s vocabulary. I oversee and participate in the development
			and delivery of all data-driven products and services at JSM.
		    \item \textbf{Developing \href{http://smarthealth.ai}{Smarthealth.ai}} I
			have been involved in the design and development of Smarthealth.ai, a
			platform for generating, storing and analyzing electronic health
			records. Doctors, patients and hospitals all use this platform to
			create EHRs in a structured way. I have developed various machine
			learning plugins for the Smarthealth platform which allow it to -
			\begin{itemize}
			    \item parse and convert unstructured medical text and other records
				into structured, analyzable data
			    \item generate recommendations for users across various kinds of
				sections in an EHR
			    \item automatically code medical information using SNOMED CT - a
				hierarchical medical terminology coding standard - which allows users
				to better query their data.
			\end{itemize}
		    \item \textbf{Building Recommendation Systems for an online Video Streaming Service}
			I built a content-based recommendation system for
			varied video containing feature-length video clips as well as short
			videos, working with a variety of features like the video metadata
			and other annotations. This recommendation system was also ported to
			Apache Spark before the final deployment.
		\end{itemize}
	\end{rSubsection}

\begin{rSubsection}{Cube26 Software Pvt Ltd}{Novemer 2015 - December 2016}{Data
    Scientist}{New Delhi}
\begin{itemize}
\item \textbf{Design, implementation and maintenance of machine learning resources for the \href{http://bit.ly/2bB0uGK}{ReosMessage app}.}
    The \href{http://bit.ly/2bB0uGK}{ReosMessage app} is an SMS app for Android
    that improves user experience in a data-driven way. I am handling the data
    science side of some of these features in the app. I have built and am
    maintaining the machine learning models that the app uses to classify
    messages into categories like personal, transactional (banking transactions,
    recharge notifications, OTPs) and spam. The app receives millions of
    messages per month. I am in-charge of leveraging this dataset to improve
    the classification accuracy of different machine learning models used for
    the app. My preprocessing libraries use Apache Spark and pandas, and the
    machine learning models are built with scikit-learn. I also have built
    a backend library that continuously benchmarks different algorithms against
    this dataset, and keeps picking the the algorithm with the best performance
    for the app. The algorithm also needs to be ported to the Android frontend.
    I have also developed and am maintaining a library that uses Android's
    Native Development Kit to port machine learning algorithms in C++ into a
    system library that the Android code uses.
\item \textbf{Design and deployment of server-side code for various data-driven applications.}
    There are various other data-intensive projects at Cube26, like search for
    music, videos and wikipedia articles that involves my work. I have built a
    natural language interface using NLTK, word2vec (gensim) for the
    Elasticsearch indexes that store this data. This interface turns English
    language queries into Elasticsearch queries and uses them to run the
    search.
\item \textbf{Building deep learning models for applications in computer vision and NLP.}
    The \href{http://bit.ly/2dlIoNg}{Reos Camera App} has a feature called
    "artify" which takes the input image from the camera and uses a
    convolutional neural network (CNN) to learn the "styles" from the painting
    to apply this style to the input image. I am a part of the team that built
    and trained this CNN. We used the Keras library with a theano backend to
    implement the CNN and have deployed it on an nVIDIA Titan X GPU for
    production.
\end{itemize}
\end{rSubsection}

\begin{rSubsection}{iDataLabs}{September 2015 - December 2015}{Consultant}{New Delhi}
\item \textbf{Developing a model for predicting marketing leads for software vendors.}
    This project consisted mainly of taking data provided by different software
    vendors, augmented it with the proprietory data curated by iDataLabs and
    building a prediction model with scikit-learn, after doing exhaustive grid
    search analysis, to generate marketing leads that had a high likelihood of
    paying off.

\end{rSubsection}

\begin{rSubsection}{DataCulture Analytics}{January 2015 - September 2015}{Chief
    Data Scientist}{New Delhi}
\begin{itemize}
\item \textbf{Developing a predictive analytics platform for e-commerce and logistics solutions.}
    This was a fairly open-ended and broad project which involved us building a
    dashboard which would show real time statistics for common metrics used in
    the logistics industry. I used Apache Spark to develop streaming
    applications which would compute these metrics and feed them into a
    database from which the database would read. Clients like Delhivery,
    Snapdeal, Junglee games were able to use this dashboard to monitor the
    performance of their logistics infrastructure.
\item \textbf{Building and maintaining a recommendation system for recommending logistics partners for various e-commerce companies.}
    Different online marketplaces have a number of options when it comes to
    getting products delivered from the sellers to the buyers. This project
    involved building a content-based recommendation system to recommend the
    best possible logistics solutions to the vendor - based on where the buyer
    and the seller were located and using other features based on the item
    being transported.

\end{itemize}
\end{rSubsection}

\begin{rSubsection}{Enthought, Inc}{April 2012 - December 2015}{Scientific
    Software Developer}{Mumbai}
\begin{itemize}
\item \textbf{Developing automated data analysis and visualization software.}
    The \href{https://www.enthought.com/products/canopy/}{Canopy Data Analysis environment} contains an
    integrated environment for automating basic exploratory data analysis. I
    developed this environment using Enthought's internal GUI toolkits and a
    combination of numerical libraries in Python like Pandas, Scikit-Learn and
    matplotlib.
\item \textbf{Core developer of the Canopy Python distribution and data analysis environemnt.}
    I was involved in the design, maintainance and debugging of the Canopy
    project from its beginning in various capacities.
\item \textbf{Built a continuous integration and delivery platform from scratch.}
    When I started working at Enthought, I was tasked with building and
    maintaining a QA system. I used Jenkins to automate the running of various
    unit and integration tests within Canopy, building the package and then
    running system tests on it. I helped the entire development effort move to
    a continuous integration paradigm and speed up the development cycle
    drastically.
\end{itemize}
\end{rSubsection}

\begin{rSubsection}{Tata Institute of Fundamental Research}{August 2011 -
    January 2012}{Research Assistant}{Mumbai}
\begin{itemize}
\item Analysis of data from various applications in material sciences and
    experimental physics.
\item Developed a system for measuring the elastic constants of solids from
    ultrasonic signals.
\end{itemize}
\end{rSubsection}

\begin{rSubsection}{University of Pune}{January 2009 - March 2012}{Research
    Assistant}{Pune}
\item Various projects in signal and image processing.
\end{rSubsection}

\begin{rSection}{Selected Talks}
    \begin{itemize}
        \item \href{https://youtu.be/mCQYXHJKZW8?t=5351}
            {Practical Image Classification \& Object Detection, PyData Delhi 2018}
            [\href{https://speakerdeck.com/jaidevd/practical-image-classification-and-object-detection}{Slides}]
        \item \href{https://www.youtube.com/watch?v=i5Rw1ITA-Ic}
            {Continuous Integration for Data Scientists, PyCon India 2016}
            [\href{https://github.com/jaidevd/jaidevd.github.io/blob/source/blog/posts/continuous-integration-for-data-scientists.ipynb}{Slides}]
        \item \href{https://www.youtube.com/watch?v=iPz0Cd84Zro}
            {Automatic Data Validation \& Cleaning with PySemantic, PyDelhi Conference, 2017}
    \end{itemize}
\end{rSection}

\end{rSection}
\begin{rSection}{Training Sessions}
    \item (Click on an item to see the workshop content used.)
    \begin{itemize}
        \item
            \href{https://github.com/jaidevd/ipec-fdp}
            {FDP on High Performance Computing -
             Inderprastha Engineering College, Ghaziabad.}
        \item
            \href{https://github.com/jaidevd/talentsprint-workshop}
            {Introduction to Machine Learning - Talentsprint, Hyderabad}
        \item \href{https://github.com/jaidevd/inmantec_fdp}{FDP on Scientific
            Computing with Python - InManTEC Institutes, Ghaziabad}
            [\href{https://sites.google.com/a/inmantec.edu/fdp/videos-and-images}{Video}]
        \item \href{https://github.com/jaidevd/scipy-2017-workshop}
            {Model Evaluation and Selection with scikit-learn, SciPy India 2017}
        \item \href{https://github.com/jaidevd/iiml_textmining}
            {Text Mining with Python, IIM Lucknow}
        \item \href{https://github.com/jaidevd/theano_nn_tutorial}
            {Understanding Neural Networks with Theano - PyDelhi Conference, 2017}
            [\href{https://www.youtube.com/watch?v=H1JNDSpZ3FY}{Video}]
        \item \href{https://github.com/jaidevd/scipy_pandas_tutorial}
            {Pandas Tutorial, SciPy India 2013}
    \end{itemize}
\end{rSection}


\begin{rSection}{Publications}

All papers have Jaidev Deshpande as the first author.

\begin{enumerate}

\item \textit{Parameterization of Traffic Flow Using Sammon-Fuzzy Clustering} 
    IEEE International Conference in Vehicular Electronics and Safety 2009
\item \textit{pyhht: A Python Toolbox for the Hilbert-Huang Transform} 
    International Conference on Python in Scientific Computing, 2011, IIT Bombay
\item \textit{Mechanism Design for Evolutionary Games in Special Interest
    Groups} 
    11th Conference of the Society of Social Choice and Welfare, Aug 2012
\item \textit{Exploratory Data Analysis with Python} \\ 
    Tutorial at the Fifth Elephant Conference on Big Data, Bangalore, July 2012
\item \textit{Fourier and Hilbert - Two Views of Nonlinear Mechanics} \\ 
    IEEE National Students Conference 2012, Pune
\item \textit{Time-Frequency Analysis with Python} 
    International Conference on Python in Scientific Computing, 2012, IIT Bombay
\item \textit{Compressed Sensing Solvers in Python} 
    International Conference on Python in Scientific Computing, 2013, IIT Bombay

\end{enumerate}

\end{rSection}

%----------------------------------------------------------------------------------------
%	TECHNICAL STRENGTHS SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Technical Strengths}

\begin{tabular}{ @{} >{\bfseries}l @{\hspace{6ex}} l }
Programming languages & Python, R, MATLAB, C, Lua\\
Software development & Continuous delivery and deployment, build and test
    infrastructure setups\\
CI Tools & Working knowledge of Jenkins and Travis\\
Virtualization & Working knowledge of Vagrant, Packer, Virtualbox and VMWare\\
Other tools & LATEX, Mathematica, etc.
\end{tabular}

\end{rSection}


\begin{rSection}{Other Projects}
    \begin{itemize}
\item Mentor for pgmpy organization in the Google Summer of Code 2015 for projects dealing with sampling and approximate algorithms for probabilistic graphical models.
\item Co-Mentor for the scikit-learn organization in Google Summer of Code 2014 for a project dealing with linear models.
\item Mathematical modeling of centralized admission procedures (Sept 08 to Jan 09) (2nd prize in Avishkar Inter-varsity Research Festival 2009)
\item Empirical mode secomposition based feature extraction for speech recognition (Feb 10 to May 10, course requirement)
\item Analysis of empirical mode decomposition as a feature extraction method. (March 11 to Present)
\item Development of an open-source toolbox for adaptive data analysis (July 11 to Dec 11, course requirement)
\item Scikit-signal - A Python toolbox for signal processing (Jan 12 to Present)
\item PyHHT - A Python toolbox for the Hilbert-Huang Transform (Jan 12 to Present)
    \end{itemize}
\end{rSection}


\begin{rSection}{Achievements}
    \begin{itemize}
        \item Earned a distinction in the Computing for Data Analysis class
            offered by Coursera.
        \item Earned a distinction in the Data Scientistâ€™s Toolbox class
            offered by Coursera.
        \item Semi-finalist in the ARI Atlas Shrugged Essay Contest â€™09.
        \item Represented west zone in Avishkar Inter-varsity Research Festival
            2008-09, won the first prize in the Humanities category.
        \item Editor of the college magazine Lighthouse in 2008 and 2009.
        \item Held 6th position in national debate contest organized by ToI and
            the Lok-Satta Party.
    \end{itemize}
\end{rSection}

\begin{rSection}{Other Acitivities}
    \begin{itemize}
        \item Active member of the Pune, Mumbai and Delhi Python users' groups.
        \item Co-founder of a forum for scientific computing in Pune.
        \item Active member of the Ayn Rand in India intiative.
        \item Active member of the IEEE.
    \end{itemize}
\end{rSection}

\begin{rSection}{Hobbies}
    Reading, Writing, Music, Movies
\end{rSection}

\end{document}
