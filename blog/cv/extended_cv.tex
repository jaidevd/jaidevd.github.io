\documentclass{resume} % Use the custom resume.cls style

\usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry} % Document margins
\usepackage{hyperref}
\hypersetup{colorlinks=true}

\name{Jaidev Deshpande} % Your name
\address{E-12, First Floor \\ Greater Kailash 1 \\ New Delhi 110048} % Your address
\address{(+91)-844-733-5686 \\ deshpande.jaidev@gmail.com} % Your phone number and email
\address{Website: \url{http://jaidevd.github.io}}

\begin{document}

%----------------------------------------------------------------------------------------
%	EDUCATION SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Education}

{\bf University of Pune} \hfill {\em July 2012} \\ 
B.E. in Electronics

\end{rSection}

%----------------------------------------------------------------------------------------
%	WORK EXPERIENCE SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Experience}

\begin{rSubsection}{Cube26 Software Pvt Ltd}{Novemer 2015 - Present}{Data
    Scientist}{New Delhi}
\item {\bf Design, implementation and maintenance of machine learning resources for
    the \href{http://bit.ly/2bB0uGK}{ReosMessage app}.}\\
    The \href{http://bit.ly/2bB0uGK}{ReosMessage app} is an SMS app for Android
    that improves user experience in a data-driven way. I am handling the data
    science side of some of these features in the app. I have built and am
    maintaining the machine learning models that the app uses to classify
    messages into categories like personal, transactional (banking transactions,
    recharge notifications, OTPs) and spam. The app receives millions of
    messages per month. I am in-charge of leveraging this dataset to improve
    the classification accuracy of different machine learning models used for
    the app. My preprocessing libraries use Apache Spark and pandas, and the
    machine learning models are built with scikit-learn. I also have built
    a backend library that continuously benchmarks different algorithms against
    this dataset, and keeps picking the the algorithm with the best performance
    for the app. The algorithm also needs to be ported to the Android frontend.
    I have also developed and am maintaining a library that uses Android's
    Native Development Kit to port machine learning algorithms in C++ into a
    system library that the Android code uses.
\item {\bf Design and deployment of server-side code for various data-driven
    applications.}\\
    There are various other data-intensive projects at Cube26, like search for
    music, videos and wikipedia articles that involves my work. I have built a
    natural language interface using NLTK, word2vec (gensim) for the
    Elasticsearch indexes that store this data. This interface turns English
    language queries into Elasticsearch queries and uses them to run the
    search.
\item {\bf Building deep learning models for applications in computer vision and
    NLP.}\\
    The \href{http://bit.ly/2dlIoNg}{Reos Camera App} has a feature called
    "artify" which takes the input image from the camera and uses a
    convolutional neural network (CNN) to learn the "styles" from the painting
    to apply this style to the input image. I am a part of the team that built
    and trained this CNN. We used the Keras library with a theano backend to
    implement the CNN and have deployed it on an nVIDIA Titan X GPU for
    production.
\end{rSubsection}

\begin{rSubsection}{iDataLabs}{September 2015 - December 2015}{Consultant}{New
    Delhi}
\item {\bf Developing a model for predicting marketing leads for software vendors.}\\
    This project consisted mainly of taking data provided by different software
    vendors, augmented it with the proprietory data curated by iDataLabs and
    building a prediction model with scikit-learn, after doing exhaustive grid
    search analysis, to generate marketing leads that had a high likelihood of
    paying off.

\end{rSubsection}

\begin{rSubsection}{DataCulture Analytics}{January 2015 - September 2015}{Chief
    Data Scientist}{New Delhi}
\item {\bf Developing a predictive analytics platform for e-commerce and logistics
    solutions.}\\
    This was a fairly open-ended and broad project which involved us building a
    dashboard which would show real time statistics for common metrics used in
    the logistics industry. I used Apache Spark to develop streaming
    applications which would compute these metrics and feed them into a
    database from which the database would read. Clients like Delhivery,
    Snapdeal, Junglee games were able to use this dashboard to monitor the
    performance of their logistics infrastructure.
\item {\bf Building and maintaining a recommendation system for recommending
    logistics partners for various e-commerce companies.}\\
    Different online marketplaces have a number of options when it comes to
    getting products delivered from the sellers to the buyers. This project
    involved building a content-based recommendation system to recommend the
    best possible logistics solutions to the vendor - based on where the buyer
    and the seller were located and using other features based on the item
    being transported.

\end{rSubsection}

\begin{rSubsection}{Enthought, Inc}{April 2012 - December 2015}{Scientific
    Software Developer}{Mumbai}
\item {\bf Developing automated data analysis and visualization software.}\\
    The \href{https://www.enthought.com/products/canopy/}{Canopy Data Analysis environment} contains an
    integrated environment for automating basic exploratory data analysis. I
    developed this environment using Enthought's internal GUI toolkits and a
    combination of numerical libraries in Python like Pandas, Scikit-Learn and
    matplotlib.
\item {\bf Core developer of the Canopy Python distribution and data analysis
    environemnt.}\\
    I was involved in the design, maintainance and debugging of the Canopy
    project from its beginning in various capacities.
\item {\bf Built a continuous integration and delivery platform from scratch.}\\
    When I started working at Enthought, I was tasked with building and
    maintaining a QA system. I used Jenkins to automate the running of various
    unit and integration tests within Canopy, building the package and then
    running system tests on it. I helped the entire development effort move to
    a continuous integration paradigm and speed up the development cycle
    drastically.
\end{rSubsection}

\begin{rSubsection}{Tata Institute of Fundamental Research}{August 2011 -
    January 2012}{Research Assistant}{Mumbai}
\item Analysis of data from various applications in material sciences and
    experimental physics.
\item Developed a system for measuring the elastic constants of solids from
    ultrasonic signals.
\end{rSubsection}

\begin{rSubsection}{University of Pune}{January 2009 - March 2012}{Research
    Assistant}{Pune}
\item Various projects in signal and image processing.
\end{rSubsection}

\end{rSection}


\begin{rSection}{Publications \& Talks}

All papers have Jaidev Deshpande as the first author.

\begin{enumerate}

\item \textit{Parameterization of Traffic Flow Using Sammon-Fuzzy Clustering} \\
    IEEE International Conference in Vehicular Electronics and Safety 2009
\item \textit{pyhht: A Python Toolbox for the Hilbert-Huang Transform} \\
    International Conference on Python in Scientific Computing, 2011, IIT Bombay
\item \textit{Mechanism Design for Evolutionary Games in Special Interest
    Groups} \\
    11th Conference of the Society of Social Choice and Welfare, Aug 2012
\item \textit{Exploratory Data Analysis with Python} \\ 
    Tutorial at the Fifth Elephant Conference on Big Data, Bangalore, July 2012
\item \textit{Fourier and Hilbert - Two Views of Nonlinear Mechanics} \\ 
    IEEE National Students Conference 2012, Pune
\item \textit{Time-Frequency Analysis with Python} \\
    International Conference on Python in Scientific Computing, 2012, IIT Bombay
\item \textit{Compressed Sensing Solvers in Python} \\
    International Conference on Python in Scientific Computing, 2013, IIT Bombay

\end{enumerate}

Several more talks and tutorial sessions on Python and data analysis delivered at various meetings.

\end{rSection}

%----------------------------------------------------------------------------------------
%	TECHNICAL STRENGTHS SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Technical Strengths}

\begin{tabular}{ @{} >{\bfseries}l @{\hspace{6ex}} l }
Programming languages & Python, R, MATLAB, C, Lua\\
Software development & Continuous delivery and deployment, build and test infrastructure setups\\
CI Tools & Working knowledge of Jenkins and Travis\\
Virtualization & Working knowledge of Vagrant, Packer, Virtualbox and VMWare \\
Other tools & LATEX, Mathematica, etc.
\end{tabular}

\end{rSection}


\begin{rSection}{Other Projects}
    \begin{itemize}
\item Mentor for pgmpy organization in the Google Summer of Code 2015 for projects dealing with sampling and approximate algorithms for probabilistic graphical models.
\item Co-Mentor for the scikit-learn organization in Google Summer of Code 2014 for a project dealing with linear models.
\item Mathematical modeling of centralized admission procedures (Sept 08 to Jan 09) (2nd prize in Avishkar Inter-varsity Research Festival 2009)
\item Empirical mode secomposition based feature extraction for speech recognition (Feb 10 to May 10, course requirement)
\item Analysis of empirical mode decomposition as a feature extraction method. (March 11 to Present)
\item Development of an open-source toolbox for adaptive data analysis (July 11 to Dec 11, course requirement)
\item Scikit-signal - A Python toolbox for signal processing (Jan 12 to Present)
\item PyHHT - A Python toolbox for the Hilbert-Huang Transform (Jan 12 to Present)
    \end{itemize}
\end{rSection}


\begin{rSection}{Achievements}
    \begin{itemize}
        \item Earned a distinction in the Computing for Data Analysis class
            offered by Coursera.
        \item Earned a distinction in the Data Scientist’s Toolbox class
            offered by Coursera.
        \item Semi-finalist in the ARI Atlas Shrugged Essay Contest ’09.
        \item Represented west zone in Avishkar Inter-varsity Research Festival
            2008-09, won the first prize in the Humanities category.
        \item Editor of the college magazine Lighthouse in 2008 and 2009.
        \item Held 6th position in national debate contest organized by ToI and
            the Lok-Satta Party.
    \end{itemize}
\end{rSection}

\begin{rSection}{Other Acitivities}
    \begin{itemize}
        \item Active member of the Pune, Mumbai and Delhi Python users' groups.
        \item Co-founder of a forum for scientific computing in Pune.
        \item Active member of the Ayn Rand in India intiative.
        \item Active member of the IEEE.
    \end{itemize}
\end{rSection}

\begin{rSection}{Hobbies}
    Reading, Writing, Music, Movies
\end{rSection}

\end{document}
